{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab today, we will run the kNN model to determine the best ‘k’ value in order to determine whether a wine is of high quality. \n",
    "\n",
    "We will use the following features: ‘density’, ‘sulphates’, residual sugar’.\n",
    "\n",
    "Please check 'k' values from 1 to 50 in order to determine the best 'k' value.\n",
    "\n",
    "Below is start code which obtains demo data from Amazon Web Services website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df = pd.read_csv(\"https://s3.amazonaws.com/demo-datasets/wine.csv\")\n",
    "\n",
    "test_idx = np.random.uniform(0, 1, len(df)) <= 0.3\n",
    "train = df[test_idx==True]\n",
    "test = df[test_idx==False]\n",
    "\n",
    "features = ['density', 'sulphates', 'residual_sugar']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Filtering the train and test sets\n",
    "train_features = train[features]\n",
    "\n",
    "test_features = test[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#high quality is our target, and is binary.\n",
    "train_target = train.high_quality\n",
    "\n",
    "test_target = test.high_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Time to set up a KNeighbors from 1 to 50...\n",
    "neigh = {}\n",
    "for i in range(50):\n",
    "    neigh[i+1] = KNeighborsClassifier(n_neighbors=i+1).fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of KNN classification of 1 neighbors on this test set is: 0.738943\n",
      "\n",
      "The accuracy of KNN classification of 2 neighbors on this test set is: 0.787702\n",
      "\n",
      "The accuracy of KNN classification of 3 neighbors on this test set is: 0.752751\n",
      "\n",
      "The accuracy of KNN classification of 4 neighbors on this test set is: 0.779072\n",
      "\n",
      "The accuracy of KNN classification of 5 neighbors on this test set is: 0.769579\n",
      "\n",
      "The accuracy of KNN classification of 6 neighbors on this test set is: 0.792017\n",
      "\n",
      "The accuracy of KNN classification of 7 neighbors on this test set is: 0.780798\n",
      "\n",
      "The accuracy of KNN classification of 8 neighbors on this test set is: 0.793096\n",
      "\n",
      "The accuracy of KNN classification of 9 neighbors on this test set is: 0.789213\n",
      "\n",
      "The accuracy of KNN classification of 10 neighbors on this test set is: 0.796764\n",
      "\n",
      "The accuracy of KNN classification of 11 neighbors on this test set is: 0.789213\n",
      "\n",
      "The accuracy of KNN classification of 12 neighbors on this test set is: 0.793528\n",
      "\n",
      "The accuracy of KNN classification of 13 neighbors on this test set is: 0.785976\n",
      "\n",
      "The accuracy of KNN classification of 14 neighbors on this test set is: 0.790507\n",
      "\n",
      "The accuracy of KNN classification of 15 neighbors on this test set is: 0.787918\n",
      "\n",
      "The accuracy of KNN classification of 16 neighbors on this test set is: 0.794606\n",
      "\n",
      "The accuracy of KNN classification of 17 neighbors on this test set is: 0.793312\n",
      "\n",
      "The accuracy of KNN classification of 18 neighbors on this test set is: 0.797627\n",
      "\n",
      "The accuracy of KNN classification of 19 neighbors on this test set is: 0.796117\n",
      "\n",
      "The accuracy of KNN classification of 20 neighbors on this test set is: 0.798706\n",
      "\n",
      "The accuracy of KNN classification of 21 neighbors on this test set is: 0.796117\n",
      "\n",
      "The accuracy of KNN classification of 22 neighbors on this test set is: 0.797843\n",
      "\n",
      "The accuracy of KNN classification of 23 neighbors on this test set is: 0.797411\n",
      "\n",
      "The accuracy of KNN classification of 24 neighbors on this test set is: 0.799137\n",
      "\n",
      "The accuracy of KNN classification of 25 neighbors on this test set is: 0.798490\n",
      "\n",
      "The accuracy of KNN classification of 26 neighbors on this test set is: 0.797843\n",
      "\n",
      "The accuracy of KNN classification of 27 neighbors on this test set is: 0.798706\n",
      "\n",
      "The accuracy of KNN classification of 28 neighbors on this test set is: 0.800216\n",
      "\n",
      "The accuracy of KNN classification of 29 neighbors on this test set is: 0.799569\n",
      "\n",
      "The accuracy of KNN classification of 30 neighbors on this test set is: 0.799353\n",
      "\n",
      "The accuracy of KNN classification of 31 neighbors on this test set is: 0.798706\n",
      "\n",
      "The accuracy of KNN classification of 32 neighbors on this test set is: 0.798921\n",
      "\n",
      "The accuracy of KNN classification of 33 neighbors on this test set is: 0.798706\n",
      "\n",
      "The accuracy of KNN classification of 34 neighbors on this test set is: 0.799137\n",
      "\n",
      "The accuracy of KNN classification of 35 neighbors on this test set is: 0.799784\n",
      "\n",
      "The accuracy of KNN classification of 36 neighbors on this test set is: 0.800647\n",
      "\n",
      "The accuracy of KNN classification of 37 neighbors on this test set is: 0.800000\n",
      "\n",
      "The accuracy of KNN classification of 38 neighbors on this test set is: 0.800863\n",
      "\n",
      "The accuracy of KNN classification of 39 neighbors on this test set is: 0.800647\n",
      "\n",
      "The accuracy of KNN classification of 40 neighbors on this test set is: 0.800863\n",
      "\n",
      "The accuracy of KNN classification of 41 neighbors on this test set is: 0.800863\n",
      "\n",
      "The accuracy of KNN classification of 42 neighbors on this test set is: 0.800647\n",
      "\n",
      "The accuracy of KNN classification of 43 neighbors on this test set is: 0.800863\n",
      "\n",
      "The accuracy of KNN classification of 44 neighbors on this test set is: 0.800647\n",
      "\n",
      "The accuracy of KNN classification of 45 neighbors on this test set is: 0.800647\n",
      "\n",
      "The accuracy of KNN classification of 46 neighbors on this test set is: 0.800647\n",
      "\n",
      "The accuracy of KNN classification of 47 neighbors on this test set is: 0.800647\n",
      "\n",
      "The accuracy of KNN classification of 48 neighbors on this test set is: 0.800647\n",
      "\n",
      "The accuracy of KNN classification of 49 neighbors on this test set is: 0.800647\n",
      "\n",
      "The accuracy of KNN classification of 50 neighbors on this test set is: 0.800647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking that the dictionary is from 1 to 50 for k neighbors.\n",
    "scores = {}\n",
    "for i in range(50):\n",
    "    neigh[i+1].predict(test_features)\n",
    "    print (\"The accuracy of KNN classification of %i neighbors on this test set is: %f\" % (i+1, neigh[i+1].score(test_features, test_target)))\n",
    "    print \"\"\n",
    "    scores[i+1]= neigh[i+1].score(test_features, test_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of K nearest neighbors with the best accuracy score is: 38\n",
      "The score itself is 0.800862998921\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"The number of K nearest neighbors with the best accuracy score is:\", max(scores, key=scores.get)\n",
    "print \"The score itself is\", scores[max(scores, key=scores.get)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression.\n",
    "\n",
    "Now that we've run a k nearest neighbors and found that 38 is the best 'k' value, let's look at logistic. We are first going to look at sklearn, where we apply regularization with L2 as the penalty setting automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logit = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting the model.\n",
    "model = logit.fit(train_features, train_target)\n",
    "predict_logit = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the logit is: 0.800647249191\n",
      "\n",
      "The difference in accuracy between this logistic and the k nearest neighbors is: -0.000215749730313\n"
     ]
    }
   ],
   "source": [
    "#What's the accuracy of logistic with regularization?\n",
    "\n",
    "print \"The accuracy of the logit is:\", logit.score(test_features, test_target)\n",
    "print \"\"\n",
    "print \"The difference in accuracy between this logistic and the k nearest neighbors is:\", (logit.score(test_features, test_target)-scores[max(scores, key=scores.get)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression continued...\n",
    "\n",
    "So we looked at logistic regression using sklearn. I am actually interested in seeing the regression output, so I am going to look at logistic with statsmodels.\n",
    "\n",
    "I will look at the logistic and then try to regularize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting the logistic model. Binary, so should only need Logit.\n",
    "\n",
    "logit_quality = sm.Logit(train_target, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.479912\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>high_quality</td>   <th>  No. Observations:  </th>  <td>  1862</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1859</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 04 May 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.01174</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>00:18:50</td>     <th>  Log-Likelihood:    </th> <td> -893.60</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -904.22</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>2.443e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>        <td>   -1.9022</td> <td>    0.249</td> <td>   -7.647</td> <td> 0.000</td> <td>   -2.390    -1.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>      <td>    1.1641</td> <td>    0.399</td> <td>    2.921</td> <td> 0.003</td> <td>    0.383     1.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual_sugar</th> <td>   -0.0366</td> <td>    0.014</td> <td>   -2.674</td> <td> 0.007</td> <td>   -0.063    -0.010</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           high_quality   No. Observations:                 1862\n",
       "Model:                          Logit   Df Residuals:                     1859\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Wed, 04 May 2016   Pseudo R-squ.:                 0.01174\n",
       "Time:                        00:18:50   Log-Likelihood:                -893.60\n",
       "converged:                       True   LL-Null:                       -904.22\n",
       "                                        LLR p-value:                 2.443e-05\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------\n",
       "density           -1.9022      0.249     -7.647      0.000        -2.390    -1.415\n",
       "sulphates          1.1641      0.399      2.921      0.003         0.383     1.945\n",
       "residual_sugar    -0.0366      0.014     -2.674      0.007        -0.063    -0.010\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_quality_results = logit_quality.fit()\n",
    "logit_quality_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#How does this model do on the test data?\n",
    "\n",
    "predictions = pd.Series(logit_quality_results.predict(test_features), index = test_target.index)\n",
    "combined = pd.concat([test_target, predictions], axis = 1, ignore_index = False)\n",
    "combined.columns = ['high quality actual', 'predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined['difference'] = combined['high quality actual'] - combined.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high quality actual</th>\n",
       "      <th>predictions</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231533</td>\n",
       "      <td>-0.231533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227233</td>\n",
       "      <td>-0.227233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215387</td>\n",
       "      <td>-0.215387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211542</td>\n",
       "      <td>-0.211542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212153</td>\n",
       "      <td>-0.212153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.199611</td>\n",
       "      <td>0.800389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.213195</td>\n",
       "      <td>0.786805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206757</td>\n",
       "      <td>-0.206757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266163</td>\n",
       "      <td>-0.266163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.251785</td>\n",
       "      <td>0.748215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385017</td>\n",
       "      <td>-0.385017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186003</td>\n",
       "      <td>-0.186003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330711</td>\n",
       "      <td>-0.330711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206686</td>\n",
       "      <td>-0.206686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226833</td>\n",
       "      <td>-0.226833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222603</td>\n",
       "      <td>-0.222603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218568</td>\n",
       "      <td>-0.218568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290084</td>\n",
       "      <td>-0.290084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209796</td>\n",
       "      <td>-0.209796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217256</td>\n",
       "      <td>-0.217256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205311</td>\n",
       "      <td>-0.205311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210206</td>\n",
       "      <td>-0.210206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229418</td>\n",
       "      <td>-0.229418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156172</td>\n",
       "      <td>-0.156172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210877</td>\n",
       "      <td>-0.210877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188389</td>\n",
       "      <td>-0.188389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216393</td>\n",
       "      <td>-0.216393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>-0.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240913</td>\n",
       "      <td>-0.240913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196802</td>\n",
       "      <td>-0.196802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6460</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207127</td>\n",
       "      <td>-0.207127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6461</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200215</td>\n",
       "      <td>-0.200215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6462</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.190577</td>\n",
       "      <td>0.809423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200787</td>\n",
       "      <td>-0.200787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195054</td>\n",
       "      <td>-0.195054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184029</td>\n",
       "      <td>-0.184029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212660</td>\n",
       "      <td>-0.212660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158305</td>\n",
       "      <td>-0.158305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.153275</td>\n",
       "      <td>0.846725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212171</td>\n",
       "      <td>-0.212171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161083</td>\n",
       "      <td>-0.161083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207964</td>\n",
       "      <td>-0.207964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196294</td>\n",
       "      <td>-0.196294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189312</td>\n",
       "      <td>-0.189312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.215792</td>\n",
       "      <td>0.784208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182599</td>\n",
       "      <td>-0.182599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167024</td>\n",
       "      <td>-0.167024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6480</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149153</td>\n",
       "      <td>-0.149153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6482</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175869</td>\n",
       "      <td>-0.175869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6483</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166014</td>\n",
       "      <td>-0.166014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167024</td>\n",
       "      <td>-0.167024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.302018</td>\n",
       "      <td>0.697982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.262752</td>\n",
       "      <td>0.737248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213363</td>\n",
       "      <td>-0.213363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149153</td>\n",
       "      <td>-0.149153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200679</td>\n",
       "      <td>-0.200679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212852</td>\n",
       "      <td>-0.212852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203939</td>\n",
       "      <td>-0.203939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198380</td>\n",
       "      <td>-0.198380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185640</td>\n",
       "      <td>0.814360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4635 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      high quality actual  predictions  difference\n",
       "1                     0.0     0.231533   -0.231533\n",
       "2                     0.0     0.227233   -0.227233\n",
       "3                     0.0     0.215387   -0.215387\n",
       "4                     0.0     0.211542   -0.211542\n",
       "5                     0.0     0.212153   -0.212153\n",
       "7                     1.0     0.199611    0.800389\n",
       "8                     1.0     0.213195    0.786805\n",
       "12                    0.0     0.206757   -0.206757\n",
       "14                    0.0     0.266163   -0.266163\n",
       "16                    1.0     0.251785    0.748215\n",
       "17                    0.0     0.385017   -0.385017\n",
       "18                    0.0     0.186003   -0.186003\n",
       "19                    0.0     0.330711   -0.330711\n",
       "20                    0.0     0.206686   -0.206686\n",
       "21                    0.0     0.226833   -0.226833\n",
       "24                    0.0     0.222603   -0.222603\n",
       "26                    0.0     0.218568   -0.218568\n",
       "27                    0.0     0.290084   -0.290084\n",
       "28                    0.0     0.209796   -0.209796\n",
       "29                    0.0     0.217256   -0.217256\n",
       "30                    0.0     0.205311   -0.205311\n",
       "31                    0.0     0.210206   -0.210206\n",
       "32                    0.0     0.229418   -0.229418\n",
       "33                    0.0     0.156172   -0.156172\n",
       "34                    0.0     0.210877   -0.210877\n",
       "35                    0.0     0.188389   -0.188389\n",
       "36                    0.0     0.216393   -0.216393\n",
       "38                    0.0     0.199900   -0.199900\n",
       "39                    0.0     0.240913   -0.240913\n",
       "41                    0.0     0.196802   -0.196802\n",
       "...                   ...          ...         ...\n",
       "6460                  0.0     0.207127   -0.207127\n",
       "6461                  0.0     0.200215   -0.200215\n",
       "6462                  1.0     0.190577    0.809423\n",
       "6463                  0.0     0.200787   -0.200787\n",
       "6464                  0.0     0.195054   -0.195054\n",
       "6466                  0.0     0.184029   -0.184029\n",
       "6467                  0.0     0.212660   -0.212660\n",
       "6468                  0.0     0.158305   -0.158305\n",
       "6469                  1.0     0.153275    0.846725\n",
       "6470                  0.0     0.212171   -0.212171\n",
       "6471                  0.0     0.161083   -0.161083\n",
       "6472                  0.0     0.207964   -0.207964\n",
       "6473                  0.0     0.196294   -0.196294\n",
       "6474                  0.0     0.189312   -0.189312\n",
       "6475                  1.0     0.215792    0.784208\n",
       "6476                  0.0     0.182599   -0.182599\n",
       "6479                  0.0     0.167024   -0.167024\n",
       "6480                  0.0     0.149153   -0.149153\n",
       "6482                  0.0     0.175869   -0.175869\n",
       "6483                  0.0     0.166014   -0.166014\n",
       "6484                  0.0     0.167024   -0.167024\n",
       "6485                  1.0     0.302018    0.697982\n",
       "6486                  1.0     0.262752    0.737248\n",
       "6487                  0.0     0.213363   -0.213363\n",
       "6488                  0.0     0.149153   -0.149153\n",
       "6490                  0.0     0.200679   -0.200679\n",
       "6491                  0.0     0.212852   -0.212852\n",
       "6492                  0.0     0.203939   -0.203939\n",
       "6494                  0.0     0.198380   -0.198380\n",
       "6495                  1.0     0.185640    0.814360\n",
       "\n",
       "[4635 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am assuming the fit is not good on this logistic given the R squared.\n",
    "\n",
    "I am going to attempt regularization in statsmodels.\n",
    "\n",
    "### Regularization in Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.479911524195\n",
      "            Iterations: 26\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 26\n"
     ]
    }
   ],
   "source": [
    "#Regularization...\n",
    "\n",
    "logit_reg_quality = logit_quality.fit_regularized()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that 26 iterations occured for regularization compared to six for no regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>high_quality</td>   <th>  No. Observations:  </th>  <td>  1862</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1859</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 04 May 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.01174</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>00:41:47</td>     <th>  Log-Likelihood:    </th> <td> -893.60</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -904.22</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>2.443e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>        <td>   -1.9022</td> <td>    0.249</td> <td>   -7.647</td> <td> 0.000</td> <td>   -2.390    -1.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>      <td>    1.1641</td> <td>    0.399</td> <td>    2.921</td> <td> 0.003</td> <td>    0.383     1.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual_sugar</th> <td>   -0.0366</td> <td>    0.014</td> <td>   -2.674</td> <td> 0.007</td> <td>   -0.063    -0.010</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           high_quality   No. Observations:                 1862\n",
       "Model:                          Logit   Df Residuals:                     1859\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Wed, 04 May 2016   Pseudo R-squ.:                 0.01174\n",
       "Time:                        00:41:47   Log-Likelihood:                -893.60\n",
       "converged:                       True   LL-Null:                       -904.22\n",
       "                                        LLR p-value:                 2.443e-05\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------\n",
       "density           -1.9022      0.249     -7.647      0.000        -2.390    -1.415\n",
       "sulphates          1.1641      0.399      2.921      0.003         0.383     1.945\n",
       "residual_sugar    -0.0366      0.014     -2.674      0.007        -0.063    -0.010\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_reg_quality.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit does not look good here either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Logistic regression with regularization in sklearn and K nearest neighbors both do a good job of classifying if a wine is high quality or not based on the three features passed (both have an accuracy of 80%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
